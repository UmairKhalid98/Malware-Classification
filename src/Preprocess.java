import java.io.BufferedReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.LinkedHashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.stream.Collectors;

import java.util.Map.Entry;
import java.io.File;
import java.io.FileReader;
import java.io.FileWriter;

public class Preprocess {

    // opcodeCount contains the total count of each opcode in ALL families
    // uniqueKeys contains the assigned values of unique key assigned to each opcode

    static HashMap<String, Integer> opcodeCount = new HashMap<String, Integer>();
    static HashMap<String, Integer> uniqueKeys = new HashMap<String, Integer>();
    static String mainFolder = "/Users/umairkhalid/Desktop/Classes/CS171/Midterm2/Malicia";
    static File file = new File(mainFolder);

    public static void process(int uniqueOpcodes, String newFilePath) throws Exception{
        //create directories 
        String assignedMalicia = newFilePath+"/"+"assignedMalicia";
        String data = newFilePath+"/"+"data";
        File exp = new File(newFilePath);
        File assignedMaliciaFolder = new File(assignedMalicia);
        File dataFolder = new File(data);
        exp.mkdir();
        assignedMaliciaFolder.mkdir();
        dataFolder.mkdir();

        //start process
        assignKeys(uniqueOpcodes);
        createUniqueKeySet(assignedMalicia);
        normalizeProcessedData(assignedMaliciaFolder, data, uniqueOpcodes);
    }

    public static void main(String[] args) throws Exception {
        countOpcodes();
        String path = "Exp";
        for(int i = 5; i<= 100; i+=5){
            System.out.println(path+i);
            process(i, path+i);
        }
        // assignKeys(80);
        // for (HashMap.Entry<String, Integer> entry : uniqueKeys.entrySet()) {
        //     String key = entry.getKey();
        //     int val = entry.getValue();
        //     System.out.println(val);

        // }
        // System.out.println("----");
        // System.out.println(80*(opcodeCount.size()) / 100);
        
        // String data = "data";
        

    }

    /**
     * Assign an integer as a unique key to each opcode and put that in the
     * uniquekey hashmap
     * When the allowed percentage of unique keys has reached, assigen the same
     * value to all the rest of the opcodes
     * The parameter contains the percentage of uniqueOpcodes allowed
     */
    private static void assignKeys(int uniqueOpcodes) {
        uniqueOpcodes = (uniqueOpcodes * opcodeCount.size()) / 100;
        opcodeCount = sortByValue(opcodeCount, false);
        int i = 0;
        for (HashMap.Entry<String, Integer> entry : opcodeCount.entrySet()) {
            String key = entry.getKey();
            uniqueKeys.put(key, i);
            if (i < uniqueOpcodes) {
                i++;
            }
        }

        uniqueKeys = sortByValue(uniqueKeys, true);
    }

       /**
         * For each family, read all the opcodes in each file, and count the number of
         * time each opcode appears
         */
    private static void countOpcodes() throws Exception{

        File[] maliciousFam = file.listFiles(); // List of all families (3 in this case)
        File[] listOfopcodeFiles; // list of all files within each family
        for (File f : maliciousFam) {
            // DS store is a mac folder setting file present in every directory
            if (!f.getName().equals(".DS_Store")) {
                // System.out.println(f.getName());
                listOfopcodeFiles = f.listFiles();
                for (File opcFile : listOfopcodeFiles) {
                    BufferedReader br = new BufferedReader(new FileReader(opcFile));
                    String currentFile;
                    while ((currentFile = br.readLine()) != null) {
                        if (opcodeCount.containsKey(currentFile)) {
                            opcodeCount.put(currentFile, opcodeCount.get(currentFile) + 1);
                        } else {
                            opcodeCount.put(currentFile, 1);
                        }

                    }
                    br.close();
                }
            }

        }
    }

    /**
    * Go through each file and create a new set of files with the new assigned
    * values
    */
    private static void createUniqueKeySet(String newFilePath) throws Exception{


        File newFile;

        for (File f : file.listFiles()) {
            // DS store is a mac folder setting file present in every directory
            if (!f.getName().equals(".DS_Store")) {
                
                for (File opcFile : f.listFiles()) {
                    newFile = new File(newFilePath + "/" + f.getName() + "/" + opcFile.getName());
                    makeFile(newFile, opcFile, newFilePath + "/" + f.getName());
                }
            }

        }

    }

    /**
     * Create a new file with the assignedValues
     * 
     */
    public static void makeFile(File newFile, File opcFile, String folder) throws Exception {

        FileWriter myWriter;
        BufferedReader br = new BufferedReader(new FileReader(opcFile));
        String opcode;
        File f = new File(folder);
        f.mkdir();

        newFile.createNewFile();
        // System.out.println("File created: " + newFile.getName());

        while ((opcode = br.readLine()) != null) {
            // System.out.println(opcode);
            // File newFile = new File(newFilePath+"/");

            myWriter = new FileWriter(newFile, true);
            // myWriter.write("Files in Java might be tricky, but it is fun enough!");
            myWriter.write(uniqueKeys.get(opcode) + "\n");
            myWriter.close();
            // System.out.println("Successfully wrote to the file.");
        }
        br.close();
    }

    /**
     * take in the processed folder
     * look into each family,
     * for each file in the family, count the number of each unique variable present
     * in a file
     * Divide each of the count number by the total length
     * And those points become the coordinates of that file --> a datapoint
     */
    private static void normalizeProcessedData(File folder, String data, int uniqueOpcodes) throws Exception {
        uniqueOpcodes = (uniqueOpcodes * opcodeCount.size()) / 100;
        File dataFile;
        File[] listOfopcodeFiles;
        HashMap<String, Integer> opcodeInFile = new HashMap<String, Integer>();
        String opcode;
        int filesize = 0;


        // double[][] dataArray;
        ArrayList<double[]> dataArray = new ArrayList<double[]>();
        for (File f : folder.listFiles()) {
            // DS store is a mac folder setting file present in every directory
            if (!f.getName().equals(".DS_Store")) {
                // System.out.println(f.getName());
                // dataFile = new File(data+"/"+f.getName()+".txt");
                dataFile = new File(data+"/"+"data.txt");
                dataFile.createNewFile();
                listOfopcodeFiles = f.listFiles();
                // dataArray = new double[listOfopcodeFiles.length][uniqueOpcodes];

                System.out.println(f.getName());
                for (File opcFile : listOfopcodeFiles) {
                    
                    BufferedReader br = new BufferedReader(new FileReader(opcFile));
                    filesize = 0;
                    while ((opcode = br.readLine()) != null) {
                        filesize++;
                        if (opcodeInFile.containsKey(opcode)) {
                            opcodeInFile.put(opcode, opcodeInFile.get(opcode) + 1);
                        } else {
                            opcodeInFile.put(opcode, 1);
                        }

                    }
                  
                    br.close();
                    dataArray.add(NormCalculation(opcodeInFile,filesize,uniqueOpcodes)); 
                    
                    opcodeInFile.clear();
                }
                
                arrayToFile(dataArray, dataFile);
            }

        }
    }

    public static void arrayToFile(ArrayList<double[]> dataArray,File dataFile) throws Exception{
        FileWriter myWriter;
        myWriter = new FileWriter(dataFile, true);
        double count=0;
        myWriter.write( "["+ "\n");
        for(int i=0; i<dataArray.size();i++){
            myWriter.write( "["+ "\n");
            count = 0;
            for(int j=0; j< dataArray.get(i).length;j++){
                double val = dataArray.get(i)[j];
                // val = val == null? 0:val;/
                count += val;
                myWriter.write( " "+val+",");
            }
            myWriter.write( "],"+ "\n");
        }

        myWriter.write( "]"+ "\n");
        myWriter.close();
    }

    private static double[] NormCalculation(HashMap<String, Integer> hash, int size, int uniqueOpcodes) {
        // System.out.println(uniqueOpcodes);
        double[] result = new double[uniqueOpcodes+1];
        double length = size*1.0;
        double count = 0.0;
        // Just prints out all the keys and values
        for (HashMap.Entry<String, Integer> entry : hash.entrySet()) {
            String key = entry.getKey();
            int val = entry.getValue();
            
            
            result[Integer.parseInt(key)] = (val/length)*100;
            // System.out.println(result[Integer.parseInt(key)]);
            count += (val/length)*100;
        }
        // System.out.println(count + " count--------------");
        return result;

    }



       // Sorts the hashmap in acending or decending order based on the value (taken
    // from stackoverflow)
    private static HashMap<String, Integer> sortByValue(HashMap<String, Integer> unsortMap, final boolean order) {
        List<Entry<String, Integer>> list = new LinkedList<>(unsortMap.entrySet());

        // Sorting the list based on values
        list.sort((o1, o2) -> order ? o1.getValue().compareTo(o2.getValue()) == 0
                ? o1.getKey().compareTo(o2.getKey())
                : o1.getValue().compareTo(o2.getValue())
                : o2.getValue().compareTo(o1.getValue()) == 0
                        ? o2.getKey().compareTo(o1.getKey())
                        : o2.getValue().compareTo(o1.getValue()));
        return list.stream().collect(Collectors.toMap(Entry::getKey, Entry::getValue, (a, b) -> b, LinkedHashMap::new));

    }
}

/*
 * PREPROCESSING
 * [X] Get the count of all the opcodes
 * [X] Sort them in decending order
 * [X] Assign the number of unique symbols
 * [X] Create a new folder with each family and replace the opcodes in each
 * family with the new unique variable
 * [X] Normalize it
 * [X] Cnt the number of each individual unique key in a file (ie 5 As? and the
 * length is 20, it bcms 5/20)
 * 
 */
